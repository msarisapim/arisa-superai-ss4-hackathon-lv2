{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLQn1j-OIpLS"
      },
      "source": [
        "\n",
        "# Simple training on MNE epochs\n",
        "\n",
        "The braindecode library gives you access to a large number of neural network\n",
        "architectures that were developed for EEG data decoding. This tutorial will\n",
        "show you how you can easily use any of these models to decode your own data.\n",
        "In particular, we assume that have your data in an MNE format and want to\n",
        "train one of the Braindecode models on it.\n",
        "   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgXX3DTlIpLW"
      },
      "outputs": [],
      "source": [
        "# Authors: Pierre Guetschel <pierre.guetschel@gmail.com>\n",
        "#\n",
        "# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_9JdYXKL_V4"
      },
      "outputs": [],
      "source": [
        "!pip install mne==1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "by4iYRKkI1xF"
      },
      "outputs": [],
      "source": [
        "!pip install braindecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yFB5DZhRM31S"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL1GiKXyIpLY"
      },
      "source": [
        "## Finding the model you want\n",
        "\n",
        "### Exploring the braindecode online documentation\n",
        "\n",
        "Let's suppose you recently stumbled upon the Schirrmeister 2017 article [1]_.\n",
        "In this article, the authors mention that their novel architecture ShallowConvNet\n",
        "is performing well on the BCI Competition IV 2a dataset and you would like to use\n",
        "it on your own data. Fortunately, the authors also mentioned they published their\n",
        "architecture on Braindecode!\n",
        "\n",
        "In order to use this architecture, you first need to find what is its exact\n",
        "name in Braindecode. To do so, you can visit the Braindecode online documentation\n",
        "which lists all the available models.\n",
        "\n",
        "Models list: https://braindecode.org/stable/api.html#models\n",
        "\n",
        "Alternatively, the API also provide a dictionary with all available models:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y8iSQ3nIpLY"
      },
      "outputs": [],
      "source": [
        "from braindecode.models.util import models_dict\n",
        "\n",
        "print(f'All the Braindecode models:\\n{list(models_dict.keys())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQZGS0w5IpLZ"
      },
      "source": [
        "After your investigation, you found out that the model you are looking for is\n",
        "``ShallowFBCSPNet``. You can now import it from Braindecode:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDv0XilGIpLZ"
      },
      "outputs": [],
      "source": [
        "from braindecode.models import ShallowFBCSPNet, EEGNetv4, ATCNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhRKuusuIpLa"
      },
      "source": [
        "### Examining the model\n",
        "\n",
        "Now that you found your model, you must check which parameters it expects.\n",
        "You can find this information either in the online documentation here:\n",
        ":class:`braindecode.models.ShallowFBCSPNet` or directly in the module's docstring:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YceUlai0IpLa"
      },
      "outputs": [],
      "source": [
        "print(EEGNetv4.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aKPAws8K7SR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r47mNaM2IpLa"
      },
      "source": [
        "Additionally, you might be interested in visualizing the model's architecture.\n",
        "This can be done by initializing the model and calling its ``__str__()`` method.\n",
        "To initialize it, we need to specify some parameters that we set at random\n",
        "values for now:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_O1_ENTK7UK"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "\n",
        "from braindecode.datasets import create_from_X_y,BNCI2014001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eWB7IqnoDiC"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QbMX8bAM1ab"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Expss4/train_seq_pre_gj_8in1\", token='<your_hf_token>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKxnkOxCcOPI"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AgoGPcuLYSF"
      },
      "outputs": [],
      "source": [
        "subject_id = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUx0IX2vIpLb"
      },
      "source": [
        "## Loading your own data with MNE\n",
        "\n",
        "In this tutorial, we demonstrate how to train the model on MNE data.\n",
        "MNE is quite a popular library for EEG data analysis as it provides methods\n",
        "to load data from many different file formats and a large collection of algorithms\n",
        "to preprocess it.\n",
        "However, Braindecode is not limited to MNE and can be used with numpy arrays or\n",
        "PyTorch tensors/datasets.\n",
        "\n",
        "For this example, we generate some random data containing 100 examples with each\n",
        "3 channels and 1024 time points. We also generate some random labels for our data\n",
        "that simulate a 4-class classification problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtY6pdWyY4kW"
      },
      "outputs": [],
      "source": [
        "dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9ezReyeZLzI"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBaI32GgZfru"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flzZ4dzJIpLb"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "train_dataset = dataset['train']\n",
        "X = [example['arr']for example in train_dataset]\n",
        "\n",
        "# Convert to numpy arrays or other formats if necessary\n",
        "X = np.array(X)\n",
        "\n",
        "sfreq = 250\n",
        "ch_names = [ 'F1', 'F2', 'FCZ','CP1', 'CP2', 'PZ', 'PO3', 'PO4']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdQsu2XRaRW-"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI4d57dC543F"
      },
      "outputs": [],
      "source": [
        "y = [example['label'] for example in train_dataset]\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEYBpaiPSd6D"
      },
      "outputs": [],
      "source": [
        "y_one_hot = []\n",
        "z = 0\n",
        "for x in y:\n",
        "  if x == 110:\n",
        "    z = 1\n",
        "  elif x == 120:\n",
        "    z = 2\n",
        "  elif x == 150:\n",
        "    z = 0\n",
        "  y_one_hot.append(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6QnNFySQSh-o"
      },
      "outputs": [],
      "source": [
        "y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-8NxwgISh8T"
      },
      "outputs": [],
      "source": [
        "y_one_hot = np.array(y_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYf2rDysNDHs"
      },
      "outputs": [],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vEMdvAo2A0Y"
      },
      "outputs": [],
      "source": [
        "# X = np.transpose(X, (0, 2, 1))\n",
        "\n",
        "# # Print the shape of the new array\n",
        "# print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3wZ4RQ4aVMn"
      },
      "outputs": [],
      "source": [
        "X[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-TxpzPghWDV"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Assuming your EEG data is stored in a NumPy array named `eeg_data`\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# # Reshape the data to standardize across channels (samples on axis 0)\n",
        "# reshaped_data = X.reshape(X.shape[0], -1)  # Flatten all but the first dimension\n",
        "\n",
        "# # Apply standardization\n",
        "# scaled_data = scaler.fit_transform(reshaped_data)\n",
        "\n",
        "# # Reshape back to the original format\n",
        "# scaled_data = scaled_data.reshape(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2kac475gD7v"
      },
      "outputs": [],
      "source": [
        "# scaled_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg6YxWO-72s2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# reshaped_data = X.reshape(X.shape[0], -1)  # Flatten all but the first dimension\n",
        "\n",
        "# # Apply standardization\n",
        "# exponential_moving_standardize(reshaped_data , factor_new=0.001, init_block_size=None, eps=0.0001)\n",
        "\n",
        "# # Reshape back to the original format\n",
        "# scaled_data = scaled_data.reshape(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW7V0UQnkaAr"
      },
      "outputs": [],
      "source": [
        "# scaled_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g82723tclQbp"
      },
      "outputs": [],
      "source": [
        "# from mne.filter import filter_data\n",
        "# reshaped_data = X.reshape(X.shape[0], -1)  # Flatten all but the first dimension\n",
        "\n",
        "# filtered_data = filter_data(reshaped_data, l_freq=10, h_freq = 34, sfreq = 250)\n",
        "# filtered_data = filtered_data.reshape(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY8V7lp0m2TO"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaDbZgEimuYn"
      },
      "outputs": [],
      "source": [
        "# filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67TXHp_jtZWQ"
      },
      "outputs": [],
      "source": [
        "# filtered_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYeYE-et1-_P"
      },
      "outputs": [],
      "source": [
        "# filt_raw = raw.copy().filter(l_freq=1.0, h_freq=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onAZXUSB1y5U"
      },
      "outputs": [],
      "source": [
        "# from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
        "# ica = ICA(n_components=3, max_iter=\"auto\", random_state=97)\n",
        "# ica.fit(epochs)\n",
        "# ica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBLD8MUH2pTd"
      },
      "outputs": [],
      "source": [
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
        "epochs = mne.EpochsArray(X, info = info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtEb1xLal3DA"
      },
      "outputs": [],
      "source": [
        "# xdata = Raw(epochs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e-hXcME168F"
      },
      "outputs": [],
      "source": [
        "# # raw.load_data()\n",
        "# ica.plot_sources(epochs, show_scrollbars=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoLPzYgG3qy0"
      },
      "outputs": [],
      "source": [
        "# ica.plot_components()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3yaBFGw45FP"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import FastICA\n",
        "# # X, _ = load_digits(return_X_y=True)\n",
        "# ica = FastICA(n_components=3,\n",
        "#         random_state=0,\n",
        "#         whiten='unit-variance')\n",
        "# ica_data_1 = ica.fit_transform(filtered_data[0].T)\n",
        "# ica_data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zk25YD45qZh"
      },
      "outputs": [],
      "source": [
        "# ica_data_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq89n1Ke5UgW"
      },
      "outputs": [],
      "source": [
        "# filtered_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPZ3pdjPtYhU"
      },
      "outputs": [],
      "source": [
        "# num_channels = 3  # Assuming channels are the second dimension\n",
        "\n",
        "# channel_data = []\n",
        "# for channel in range(num_channels):\n",
        "#     channel_data.append(X[:, channel])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IzW69MMxtGQ"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnvZYTNC4bgT"
      },
      "outputs": [],
      "source": [
        "# from sklearn import ica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA0oV2ft8Bse"
      },
      "outputs": [],
      "source": [
        "# xdata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeNHce0avOYU"
      },
      "outputs": [],
      "source": [
        "# xdata = epochs[0]\n",
        "# # xdata = xdata.transpose([1,0])\n",
        "# # time_samples = xdata.shape[0]\n",
        "\n",
        "# # Create the subplot grid\n",
        "# fig, axes = plt.subplots(8, 1, figsize=(10, 10))  # Adjust layout as needed\n",
        "\n",
        "# # Plot each channel on a separate subplot\n",
        "# for row in range(8):\n",
        "#     # row, col = divmod(channel, 2)  # Get row and column index for subplot\n",
        "#     axes[row].plot(xdata[250:1500, row])\n",
        "#     axes[row].set_title(f\"Channel {row+1}\")\n",
        "#     axes[row].set_xlabel(\"Time (samples)\")\n",
        "#     axes[row].set_ylabel(\"Voltage (uV)\")\n",
        "#     axes[row].grid(True)\n",
        "\n",
        "# # Adjust layout (optional)\n",
        "# fig.suptitle(\"8-Channel EEG Data (Subplots)\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvrYqHcn8rfA"
      },
      "outputs": [],
      "source": [
        "# plt.plot(xdata[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zaIPvSz1ohB"
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets import (\n",
        "    create_from_mne_raw, create_from_mne_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE62ES_nS9QF"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dCpTIfsjvsv"
      },
      "outputs": [],
      "source": [
        "# X = X.transpose([0,2,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyayhTUYPU7q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qq8n9FP21tsO"
      },
      "outputs": [],
      "source": [
        "windows_dataset = create_from_X_y(\n",
        "    X, y_one_hot, drop_last_window=False, sfreq=sfreq, ch_names=['a','b','c','d','e','f','g','h']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaaplzQD8MGX"
      },
      "outputs": [],
      "source": [
        "# from braindecode.preprocessing import (\n",
        "#     exponential_moving_standardize,\n",
        "#     preprocess,\n",
        "#     Preprocessor,\n",
        "# )\n",
        "\n",
        "# low_cut_hz = 4.0  # low cut frequency for filtering\n",
        "# high_cut_hz = 38.0  # high cut frequency for filtering\n",
        "# # Parameters for exponential moving standardization\n",
        "# factor_new = 1e-3\n",
        "# init_block_size = 1000\n",
        "\n",
        "# preprocessors = [\n",
        "#     Preprocessor(\"pick_types\", eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
        "#     # Preprocessor(\n",
        "#     #     lambda data, factor: np.multiply(data, factor),  # Convert from V to uV\n",
        "#     #     factor=1e6,\n",
        "#     # ),\n",
        "#     Preprocessor(\"filter\", l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n",
        "#     Preprocessor(\n",
        "#         exponential_moving_standardize,  # Exponential moving standardization\n",
        "#         factor_new=factor_new,\n",
        "#         init_block_size=init_block_size,\n",
        "#     ),\n",
        "# ]\n",
        "\n",
        "# # Preprocess the data\n",
        "# preprocess(windows_dataset, preprocessors, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7z7zCNuSMBO"
      },
      "outputs": [],
      "source": [
        "windows_dataset.description  # look as dataset description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqUVSrl1uCff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY84Pw28IpLb"
      },
      "source": [
        "## Training your model (scikit-learn compatible)\n",
        "\n",
        "Now that you know which model you want to use, you know how to instantiate it,\n",
        "and that we have some fake data, it is time to train the model!\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>[Skorch](https://skorch.readthedocs.io)  is a library that allows you to wrap\n",
        "   any PyTorch module into a scikit-learn-compatible classifier or regressor.\n",
        "   Braindecode provides wrappers that inherit form the original Skorch ones and simply\n",
        "   implement a few additional features that facilitate the use of Braindecode models.</p></div>\n",
        "\n",
        "To train a Braindecode model, the easiest way is by using braindecode's\n",
        "Skorch wrappers. These wrappers are :class:`braindecode.EEGClassifier` and\n",
        ":class:`braindecode.EEGRegressor`. As our fake data is a classification task,\n",
        "we will use the former.\n",
        "\n",
        "The wrapper :class:`braindecode.EEGClassifier` expects a model class as its first argument but\n",
        "to facilitate the usage, you can also simply pass the name of any braindecode model as a string.\n",
        "The wrapper automatically finds and instantiates the model for you.\n",
        "If you want to pass parameters to your model, you can give them to the wrapper\n",
        "with the prefix ``module__``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2v7fN4I3_qi"
      },
      "outputs": [],
      "source": [
        "sfreq = 250\n",
        "ch_names = [ 'F1', 'F2', 'FCZ','CP1', 'CP2', 'PZ', 'PO3', 'PO4']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLAS9yp03uoZ"
      },
      "outputs": [],
      "source": [
        "# info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
        "# epochs = mne.EpochsArray(X, info = info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrhcdwijZGk3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8upASI71WKQB"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
        "device = \"cuda\" if cuda else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2ibM87ldtt3"
      },
      "outputs": [],
      "source": [
        "from braindecode.models import EEGITNet, ATCNet, EEGInceptionMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsnpkPJcidg-"
      },
      "outputs": [],
      "source": [
        "from braindecode.models import EEGConformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PQLfV5aBdUHv"
      },
      "outputs": [],
      "source": [
        "n_classes = 3\n",
        "classes = list(range(n_classes))\n",
        "# Extract number of chans and time steps from dataset\n",
        "# n_channels = windows_dataset[0][0].shape[0]\n",
        "# input_window_samples = windows_dataset[0][0].shape[1]\n",
        "\n",
        "model = EEGITNet(\n",
        "    n_chans=8,\n",
        "    drop_prob = 0.2,\n",
        "    # final_conv_length=\"auto\",\n",
        "    n_outputs = 3,\n",
        "    sfreq = 250,\n",
        "    n_times = 866,\n",
        "    input_window_seconds = 3.464,\n",
        "\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ATqj0pAVdU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8TUzDUwmiRu"
      },
      "outputs": [],
      "source": [
        "from skorch.callbacks import LRScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICONZwlayL91"
      },
      "outputs": [],
      "source": [
        "lr = 0.0625 * 0.01\n",
        "weight_decay = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqzLjsuTIpLc"
      },
      "outputs": [],
      "source": [
        "from skorch.dataset import ValidSplit\n",
        "from braindecode import EEGClassifier\n",
        "\n",
        "\n",
        "n_epochs = 500\n",
        "net = EEGClassifier(\n",
        "    model,\n",
        "    # final_conv_length='auto',\n",
        "    criterion=torch.nn.CrossEntropyLoss,\n",
        "    optimizer=torch.optim.AdamW,\n",
        "    # optimizer__lr=lr,\n",
        "    train_split=ValidSplit(0.2),callbacks=[\n",
        "        \"accuracy\",\"f1_macro\",\n",
        "    ],\n",
        "    lr = 1e-3,\n",
        "    optimizer__weight_decay=weight_decay,\n",
        "    warm_start = True,\n",
        "    # input_window_samples = input_window_samples,\n",
        "    # n_channels = n_channels,\n",
        "    # n_classes = n_classes\n",
        "    # To train a neural network you need validation split, here, we use 20%.\n",
        "    device = device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTCZjBqpfe0B"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MvpsYfNr2-7"
      },
      "outputs": [],
      "source": [
        "i = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-FE_5ciIpLc"
      },
      "outputs": [],
      "source": [
        "for _ in range(100):\n",
        "  net.fit(windows_dataset, y = None, epochs = 1)\n",
        "  with open(f'final/ex6_epoch_{i}.pkl', 'wb') as file:\n",
        "    pickle.dump(net, file)\n",
        "  i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye2KmZXt-974"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5ac3t5ZrpVPX"
      },
      "outputs": [],
      "source": [
        "net.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhK_a3WoF2Gg"
      },
      "outputs": [],
      "source": [
        "net.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6fHnimSKhaE"
      },
      "outputs": [],
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8v9S6Ddt_iu"
      },
      "outputs": [],
      "source": [
        "with open('ex4_epoch_414.pkl', 'rb') as file:\n",
        "    best_model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV4G2-vbIpLd"
      },
      "source": [
        "The pre-trained model is accessible via the ``module_`` attribute:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZuU_dc6FAei"
      },
      "outputs": [],
      "source": [
        "# model = model.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFNoeYvVFuXa"
      },
      "outputs": [],
      "source": [
        "# with open(f'final/best_model_cpu.pkl', 'wb') as file:\n",
        "#     pickle.dump(net, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM4QU5OtDIQr"
      },
      "outputs": [],
      "source": [
        "res = best_model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yArPa4XvDZA9"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUNs4QSvrYNM"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrsbWJLBDyw9"
      },
      "outputs": [],
      "source": [
        "y_true = y_one_hot\n",
        "y_pred = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "83LE0bxbFlQo"
      },
      "outputs": [],
      "source": [
        "for i in range(len(res)):\n",
        "  print(y_true[i], ' ' ,y_pred[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sDlOSyiD4BD"
      },
      "outputs": [],
      "source": [
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcBAwQ1dDdjy"
      },
      "outputs": [],
      "source": [
        "confusion_matrix = np.zeros((np.unique(y_true).shape[0], np.unique(y_true).shape[0]))\n",
        "confusion_matrix += np.bincount([y_true * num_classes + y_pred for y_true, y_pred in zip(y_true, y_pred)]).reshape(confusion_matrix.shape)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwdPm88YD8wl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\")  # Adjust 'cmap' for color scheme\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4vhQs1LfIpLd"
      },
      "outputs": [],
      "source": [
        "print(net.module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR6qH7OgIpLd"
      },
      "source": [
        "And we can see that all the following parameters were automatically inferred\n",
        "from the training data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrbl8rNKqrue"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQqc4raiqsUQ"
      },
      "source": [
        "# GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS6crrX4tlSt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0dUlSE6sw2W"
      },
      "outputs": [],
      "source": [
        "splitted = windows_dataset.split({'train':[4456], 'test': [1100]})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpBztBRbuJ0a"
      },
      "outputs": [],
      "source": [
        "splitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrCyofhftUJD"
      },
      "outputs": [],
      "source": [
        "train_set = splitted['train']  # Session train\n",
        "test_set = splitted['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRIUaH9CrR6U"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PI-SW0RUqwzv"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# train_val_split = [\n",
        "#     tuple(train_test_split(X.indices_, test_size=0.2, shuffle=False))\n",
        "# ]\n",
        "\n",
        "# param_grid = {\n",
        "#     \"optimizer__lr\": [0.00625, 0.000625],\n",
        "# }\n",
        "\n",
        "# # By setting n_jobs=-1, grid search is performed\n",
        "# # with all the processors, in this case the output of the training\n",
        "# # process is not printed sequentially\n",
        "# search = GridSearchCV(\n",
        "#     estimator=net,\n",
        "#     param_grid=param_grid,\n",
        "#     cv=train_val_split,\n",
        "#     return_train_score=True,\n",
        "#     scoring=\"f1_macro\",\n",
        "#     refit=True,\n",
        "#     verbose=1,\n",
        "#     error_score=\"raise\",\n",
        "#     n_jobs=1,\n",
        "# )\n",
        "\n",
        "# search.fit(windows_dataset, y=None)\n",
        "# search_results = pd.DataFrame(search.cv_results_)\n",
        "\n",
        "# best_run = search_results[search_results[\"rank_test_score\"] == 1].squeeze()\n",
        "\n",
        "# best_parameters = best_run[\"params\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNuxjxIeIpLd"
      },
      "outputs": [],
      "source": [
        "print(f'{net.module_.n_chans=}\\n{net.module_.n_times=}\\n{net.module_.n_outputs=}'\n",
        "      f'\\n{net.module_.input_window_seconds=}\\n{net.module_.sfreq=}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qgBU2Arz_VUq"
      },
      "outputs": [],
      "source": [
        "net.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "geEY_QFo_qPR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TtSYFro-u_d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# Extract loss and accuracy values for plotting from history object\n",
        "results_columns = ['train_loss', 'valid_loss', 'valid_f1_macro', 'train_f1_macro', 'valid_acc']\n",
        "df = pd.DataFrame(net.history[:, results_columns], columns=results_columns,\n",
        "                  index=net.history[:, 'epoch'])\n",
        "\n",
        "# get percent of misclass for better visual comparison to loss\n",
        "df = df.assign(\n",
        "               valid_misclass=100 - 100 * df.valid_acc)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(8, 3))\n",
        "df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
        "    ax=ax1, style=['-', ':'], color='tab:blue', legend=False, fontsize=14)\n",
        "\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
        "ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "df.loc[:, [ 'valid_misclass']].plot(\n",
        "    ax=ax2, style=['-', ':'],  color='tab:red', legend=False)\n",
        "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
        "ax2.set_ylabel(\"Misclassification Rate [%]\", color='tab:red', fontsize=14)\n",
        "ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
        "ax1.set_xlabel(\"Epoch\", fontsize=14)\n",
        "\n",
        "# where some data has already been plotted to ax\n",
        "handles = []\n",
        "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
        "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
        "plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWcZ-LZo-x9n"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# from braindecode.visualization import plot_confusion_matrix\n",
        "\n",
        "# # generate confusion matrices\n",
        "# # get the targets\n",
        "# y_true = valid_set.get_metadata().target\n",
        "# y_pred = clf.predict(valid_set)\n",
        "\n",
        "# # generating confusion matrix\n",
        "# confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# # add class labels\n",
        "# # label_dict is class_name : str -> i_class : int\n",
        "# label_dict = windows_dataset.datasets[0].window_kwargs[0][1]['mapping']\n",
        "# # sort the labels by values (values are integer class labels)\n",
        "# labels = [k for k, v in sorted(label_dict.items(), key=lambda kv: kv[1])]\n",
        "\n",
        "# # plot the basic conf. matrix\n",
        "# plot_confusion_matrix(confusion_mat, class_names=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evf1gaxsS-TT"
      },
      "outputs": [],
      "source": [
        "# net.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETRwIf4GcQ6-"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqF2UJf2cRk5"
      },
      "outputs": [],
      "source": [
        "test_set = load_dataset('Expss4/test_seq_for_app_donot_download',token='<your_hf_token>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSrQN0zjcZVh"
      },
      "outputs": [],
      "source": [
        "test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFo4aPj-ogcj"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzchOfmscarO"
      },
      "outputs": [],
      "source": [
        "train_dataset = test_set['train']\n",
        "X_test = [example['arr'] for example in train_dataset]\n",
        "id_test = [example['id'] for example in train_dataset]\n",
        "# Convert to numpy arrays or other formats if necessary\n",
        "X_test = np.array(X_test)\n",
        "id_test = np.array(id_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAJJbymDc9y5"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCg5jtnbwb4q"
      },
      "outputs": [],
      "source": [
        "id_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LARNd742wozY"
      },
      "outputs": [],
      "source": [
        "# Reshape to desired shape (480, 8, 867)\n",
        "desired_shape = (480, 8)\n",
        "id_test_reshaped = id_test.reshape(desired_shape)\n",
        "\n",
        "# Print the shapes for verification\n",
        "print(\"Original shape:\", id_test.shape)\n",
        "print(\"Reshaped shape:\", id_test_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF7r8jKpxTUu"
      },
      "outputs": [],
      "source": [
        "data_single_column = id_test_reshaped[:, 0].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGFLxZGzx1lV"
      },
      "outputs": [],
      "source": [
        "data_single_column.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih_gR8FPyPZu"
      },
      "outputs": [],
      "source": [
        "type(data_single_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4p72qLtySlp"
      },
      "outputs": [],
      "source": [
        "id_test = np.array(data_single_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2564Ul-EjOPb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sample EEG signal with wrong shape\n",
        "\n",
        "# Reshape to desired shape (480, 8, 867)\n",
        "desired_shape = (480, 8, 867)\n",
        "eeg_signal_reshaped = X_test.reshape(desired_shape)\n",
        "\n",
        "# Print the shapes for verification\n",
        "print(\"Original shape:\", X_test.shape)\n",
        "print(\"Reshaped shape:\", eeg_signal_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_O9u0gCp0VH"
      },
      "outputs": [],
      "source": [
        "X_test = eeg_signal_reshaped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OCS0tppc-bn"
      },
      "outputs": [],
      "source": [
        "# X_test = X_test.transpose([0,2,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8XF-d_YdBCe"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.transpose([0,2,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-77nP9hZoz5E"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo1zOVIiqYS0"
      },
      "outputs": [],
      "source": [
        "best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfwUXcPsdExf"
      },
      "outputs": [],
      "source": [
        "submit_res = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ychfISxFeJwn"
      },
      "outputs": [],
      "source": [
        "submit_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mQJw3jvqImE"
      },
      "outputs": [],
      "source": [
        "len(submit_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mRj-R0UdI5O"
      },
      "outputs": [],
      "source": [
        "tmp = []\n",
        "for x in submit_res:\n",
        "  if x == 1:\n",
        "    tmp.append(110)\n",
        "  if x == 2:\n",
        "    tmp.append(120)\n",
        "  if x == 0:\n",
        "    tmp.append(150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dP1NAhL9d9f0"
      },
      "outputs": [],
      "source": [
        "tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_MXIYWavpj-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNQJq9BGeDjW"
      },
      "outputs": [],
      "source": [
        "submit_df = pd.read_csv('/content/sample_submission-3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zTlTeAkybgv"
      },
      "outputs": [],
      "source": [
        "p = id_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7E4La3wytLH"
      },
      "outputs": [],
      "source": [
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt35fXyCv0Ws"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'predict': tmp,\n",
        "    'id': p\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcT6wTl9y-y_"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTBqXJlSefKq"
      },
      "outputs": [],
      "source": [
        "submit_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8-7-zvNzX4P"
      },
      "outputs": [],
      "source": [
        "result = pd.merge(submit_df, df[['id', 'predict']], on='id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ_fE8ghzZPq"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBPSMQv3zpID"
      },
      "outputs": [],
      "source": [
        "result = result.drop('predict_x', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZXNRc1kzwXZ"
      },
      "outputs": [],
      "source": [
        "result.rename(columns={'predict_y': 'predict'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG0nDryO0Eim"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E4_zahz0P8-"
      },
      "outputs": [],
      "source": [
        "result.loc[0:2, 'predict'] = [110, 150, 150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TIUmULE0k2v"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqnlLPRe0HqQ"
      },
      "outputs": [],
      "source": [
        "result.to_csv('mixueicecreamcha4.csv',index= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edLBmD5gepbn"
      },
      "outputs": [],
      "source": [
        "# tmp[0] = 110\n",
        "# tmp[1] = 150\n",
        "# tmp[2] = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYrio2RAejQz"
      },
      "outputs": [],
      "source": [
        "# submit_df['predict'] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P-sY_F-E7Cg"
      },
      "outputs": [],
      "source": [
        "df.to_csv('app_log.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QYMEps4E7Pw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kPJ0uAME7eA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmjRHUAQenRN"
      },
      "outputs": [],
      "source": [
        "# submit_df.to_csv('submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
