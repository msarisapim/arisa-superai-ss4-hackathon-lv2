{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcPyNpHhGrQD"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBFYNnAukz_E"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "username = userdata.get('KAGGLE_USER')\n",
        "key = userdata.get('KAGGLE_KEY')\n",
        "# Echo the credentials into the kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{{\"username\":\"{username}\",\"key\":\"{key}\"}}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NErZxxrRk8bg"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "!kaggle competitions download -c liver-ultrasound-detection\n",
        "!unzip /content/liver-ultrasound-detection.zip && rm -rf /content/liver-ultrasound-detection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cSGwnAaKEvu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFCIzkGb7Qxz"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/Colab Notebooks/Hackathon_LV2_ONLINE#2/Medical AI  OCR Hackathon/Liver Lesion/liver-ultrasound-detection.zip' '/content/liver-ultrasound-detection.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8kVLG3vBKKJ4"
      },
      "outputs": [],
      "source": [
        "!unzip /content/liver-ultrasound-detection.zip && rm -rf /content/liver-ultrasound-detection.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK78JLxwGrQJ"
      },
      "source": [
        "# Visualize Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mYleHHnDoHSs"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib==3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbhijqcVPLRc"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = '1rl1KVbin5cGeFYTfKCiTCBCFJI05g_hM'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'mapping_withPATH.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "print(f\"File downloaded as {output}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQiMKgG0GrQK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# PATH = 'C:/Users/msari/Research/Project/hackathon_lv2/liver-lesion'\n",
        "PATH = '/content'\n",
        "\n",
        "# Load the mapping file\n",
        "mapping_file_path = f'{PATH}/mapping_withPATH.csv'\n",
        "# mapping_df = pd.read_excel(mapping_file_path)\n",
        "mapping_df = pd.read_csv(mapping_file_path)\n",
        "\n",
        "# Paths to directories\n",
        "train_image_path = f'{PATH}/train/train/images/'\n",
        "train_annotation_path = f'{PATH}/train/train/annotations/'\n",
        "val_image_path = f'{PATH}/val/val/images/'\n",
        "val_annotation_path = f'{PATH}/val/val/annotations/'\n",
        "test_image_path = f'{PATH}/test/test/images/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvm567NCuczD"
      },
      "outputs": [],
      "source": [
        "mapping_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzjFySaelRT5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the mapping file\n",
        "# mapping_df = pd.read_excel(f'{PATH}/mapping.xlsx')\n",
        "# mapping_df = pd.read_csv(f'{PATH}/mapping_withPATH.csv')\n",
        "\n",
        "# Label mapping\n",
        "#Label\tDescription\n",
        "# 0\tFFC\n",
        "# 1\tFFS\n",
        "# 2\tHCC\n",
        "# 3\tcyst\n",
        "# 4\themangioma\n",
        "# 5\tdysplastic\n",
        "# 6\tCCA\n",
        "class_labels = ['FFC', 'FFS', 'HCC', 'cyst', 'hemangioma', 'dysplastic', 'CCA']\n",
        "\n",
        "def denormalize_bbox(img_shape, bbox):\n",
        "    img_height, img_width = img_shape[:2]\n",
        "    x_center, y_center, width, height = bbox\n",
        "    x_center *= img_width\n",
        "    y_center *= img_height\n",
        "    width *= img_width\n",
        "    height *= img_height\n",
        "    x1 = int(x_center - width / 2)\n",
        "    y1 = int(y_center - height / 2)\n",
        "    x2 = int(x_center + width / 2)\n",
        "    y2 = int(y_center + height / 2)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def draw_bbox(img, bbox, label):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    if label in ['HCC','CCA']:\n",
        "      color = (0, 0, 255)  # Red color for the bounding box\n",
        "    else:\n",
        "      color = (0, 255, 0)\n",
        "    thickness = 2\n",
        "    img = cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "    img = cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize_yolo_annotations(image_path, annotation_path, class_labels):\n",
        "    print(f\"Processing image: {image_path}\")\n",
        "    print(f\"Annotation file: {annotation_path}\")\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Image file not found: {image_path}\")\n",
        "        return\n",
        "    if not os.path.exists(annotation_path):\n",
        "        print(f\"Annotation file not found: {annotation_path}\")\n",
        "        return\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_with_annotations = img.copy()\n",
        "\n",
        "    with open(annotation_path, 'r') as file:\n",
        "        annotations = file.readlines()\n",
        "\n",
        "    for annotation in annotations:\n",
        "        parts = annotation.strip().split()\n",
        "        class_id = int(parts[0])\n",
        "        bbox = list(map(float, parts[1:]))\n",
        "        bbox = denormalize_bbox(img.shape, bbox)\n",
        "        img_with_annotations = draw_bbox(img_with_annotations, bbox, class_labels[class_id])\n",
        "\n",
        "    # Convert BGR to RGB for displaying with matplotlib\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_with_annotations_rgb = cv2.cvtColor(img_with_annotations, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display original and annotated images side by side\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 7))\n",
        "    axs[0].imshow(img_rgb)\n",
        "    axs[0].set_title('Original Image')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(img_with_annotations_rgb)\n",
        "    axs[1].set_title('Image with Annotations')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9lQtrR80tDP"
      },
      "outputs": [],
      "source": [
        "# Function to print the required paths and sources\n",
        "def get_paths(source, path):\n",
        "    filtered_data = data[(data['Source'] == source) & (data['PATH'] == path)]\n",
        "    data_path = []\n",
        "    for index, row in filtered_data.iterrows():\n",
        "      data_path.append([f\"train/train/images/{row['Image File']}\"])\n",
        "      # print(f\"train/train/images/{row['Image File']}\", row['Source'])\n",
        "\n",
        "    return data_path\n",
        "\n",
        "# Inputs\n",
        "data = mapping_df\n",
        "\n",
        "# Print the results\n",
        "data_path_train_machine = get_paths('machine', 'Train')\n",
        "data_path_val_machine = get_paths('machine', 'Val')\n",
        "data_path_train_mobile = get_paths('mobile', 'Train')\n",
        "data_path_val_mobile = get_paths('mobile', 'Val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvJU4EW52XY8"
      },
      "source": [
        "# Visualize single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv0tID4-nBVP"
      },
      "outputs": [],
      "source": [
        "img_num = 5551\n",
        "\n",
        "image_path = f'{PATH}/train/train/images/{img_num}.jpg'\n",
        "annotation_path = f'{PATH}/train/train/annotations/{img_num}.txt'\n",
        "visualize_yolo_annotations(image_path, annotation_path, class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8wVh19y-9Ov"
      },
      "source": [
        "# Adding Natural Glare *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfosQ7yR-oUP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def apply_brightness_contrast(input_img, brightness=0, contrast=0):\n",
        "    if brightness != 0:\n",
        "        if brightness > 0:\n",
        "            shadow = brightness\n",
        "            highlight = 255\n",
        "        else:\n",
        "            shadow = 0\n",
        "            highlight = 255 + brightness\n",
        "        alpha_b = (highlight - shadow) / 255\n",
        "        gamma_b = shadow\n",
        "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
        "    else:\n",
        "        buf = input_img.copy()\n",
        "\n",
        "    if contrast != 0:\n",
        "        f = 131 * (contrast + 127) / (127 * (131 - contrast))\n",
        "        alpha_c = f\n",
        "        gamma_c = 127 * (1 - f)\n",
        "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
        "\n",
        "    return buf\n",
        "\n",
        "def add_natural_glare(image, intensity, size):\n",
        "    h, w = image.shape[:2]\n",
        "    center_x = np.random.randint(w // 4, 3 * w // 4)\n",
        "    center_y = np.random.randint(h // 4, 3 * h // 4)\n",
        "    max_dim = max(h, w)\n",
        "    mask = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    # Create a gradient circle mask\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            dist = np.sqrt((i - center_y) ** 2 + (j - center_x) ** 2)\n",
        "            mask[i, j] = np.clip(255 - int((dist / max_dim) * 255 / size), 0, 255)\n",
        "\n",
        "    mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
        "\n",
        "    # Apply the glare effect using the mask\n",
        "    glare = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Blend glare to image\n",
        "    result = cv2.addWeighted(image, 1, glare, intensity, 0)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpC16rHODciK"
      },
      "source": [
        "## Adding Natural Glare * (Random glare_intensity, glare_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SxWgoFSHC7N7"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  # Load the image\n",
        "  image1 = cv2.imread(image_path)\n",
        "\n",
        "  # Apply random brightness and contrast adjustment\n",
        "  brightness = np.random.randint(0, 50)  # Random brightness between -50 and 50\n",
        "  contrast = np.random.randint(0, 50)    # Random contrast between -50 and 50\n",
        "  adjusted_image1 = apply_brightness_contrast(image1, brightness, contrast)\n",
        "  adjusted_image1 = apply_brightness_contrast(image1, brightness, contrast)\n",
        "\n",
        "  # Add natural glare effect with random intensity and size\n",
        "  glare_intensity = np.random.uniform(0.2, 0.5)  # Random glare intensity between 0.2 and 0.5\n",
        "  glare_size = np.random.uniform(0.3, 0.6)       # Random glare size between 0.3 and 0.6\n",
        "  adjusted_image1_with_glare = add_natural_glare(adjusted_image1, glare_intensity, glare_size)\n",
        "\n",
        "  # Show the images\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title('Original Image 1')\n",
        "  plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.title('Adjusted Image 1 with Natural Glare')\n",
        "  plt.imshow(cv2.cvtColor(adjusted_image1_with_glare, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oskecoVRvej"
      },
      "source": [
        "# Adding Moire Attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej2ICMcYSYuy"
      },
      "source": [
        "## latticegen patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NPDPQhCMR4_r"
      },
      "outputs": [],
      "source": [
        "!pip install latticegen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rx1vLgnR48p"
      },
      "outputs": [],
      "source": [
        "import latticegen\n",
        "\n",
        "r_k = 0.05\n",
        "lattice1 = latticegen.hexlattice_gen(r_k, 0, order=1)\n",
        "lattice1 = np.clip(lattice1 / lattice1.max(), 0, 1).compute()\n",
        "lattice2 = latticegen.hexlattice_gen(r_k, 5, order=1)\n",
        "lattice2 = np.clip(lattice2 / lattice2.max(), 0, 1).compute()\n",
        "\n",
        "fig,axs = plt.subplots(ncols=3, figsize=[10,4])\n",
        "for i in [0, 1]:\n",
        "    axs[i].imshow(-lattice1.T, cmap='PiYG',\n",
        "                      vmax=1,\n",
        "                      vmin=-1,\n",
        "                       alpha=lattice1.T\n",
        "                     )\n",
        "    axs[i + 1].imshow(lattice2.T, cmap='PiYG',\n",
        "                   vmax=1,\n",
        "                   vmin=-1,\n",
        "                   alpha=lattice2.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RBpUWt1R44J"
      },
      "outputs": [],
      "source": [
        "r_hBN = r_k * (0.246 / 0.2504)\n",
        "sublattice_a = latticegen.trilattice_gen(r_hBN, 0, order=1, normalize=True)\n",
        "sublattice_a = sublattice_a.compute()\n",
        "# Now add the second shifted sublattice lattice to get a hexagonal lattice\n",
        "ks = latticegen.generate_ks(r_hBN, 0, sym=6)\n",
        "x = np.array([ks[1], -ks[2]])\n",
        "shift = (np.linalg.inv(x / r_hBN).T/(3*r_k)).sum(axis=0).T  # Don't ask, this works\n",
        "sublattice_b = latticegen.trilattice_gen(r_hBN, 0, order=1,\n",
        "                                         shift=shift, normalize=True)\n",
        "sublattice_b = sublattice_b.compute()\n",
        "\n",
        "fig, axs = plt.subplots(ncols=3, figsize=[10,4])\n",
        "axs[0].set_title('Sublattice a')\n",
        "axs[1].set_title('Both sublattices')\n",
        "axs[2].set_title('Sublattice b')\n",
        "for i in [0, 1]:\n",
        "    axs[i].imshow(-sublattice_a.T, cmap='bwr',\n",
        "                  vmax=1, vmin=-1,\n",
        "                  alpha=sublattice_a.T)\n",
        "    axs[i + 1].imshow(sublattice_b.T, cmap='bwr',\n",
        "                      vmax=1, vmin=-1,\n",
        "                      alpha=sublattice_b.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fND-JAtHSO73"
      },
      "outputs": [],
      "source": [
        "sublattice_a , sublattice_a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VWjt3T0SUNn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10,10])\n",
        "plt.imshow(-sublattice_a.T, cmap='bwr',\n",
        "           vmax=1, vmin=-1,\n",
        "           alpha=sublattice_a.T)\n",
        "plt.imshow(sublattice_b.T, cmap='bwr',\n",
        "           vmax=1, vmin=-1,\n",
        "           alpha=sublattice_b.T)\n",
        "plt.imshow(lattice2.T, cmap='PiYG',\n",
        "           vmax=1, vmin=-1,\n",
        "           alpha=lattice2.T*0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsl-GhZBSd8K"
      },
      "source": [
        "## Moire Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1r1EhBaSi_m"
      },
      "outputs": [],
      "source": [
        "def normalize8(I):\n",
        "  mn = I.min()\n",
        "  mx = I.max()\n",
        "\n",
        "  mx -= mn\n",
        "\n",
        "  I = ((I - mn)/mx) * 255\n",
        "  return I.astype(np.uint8)\n",
        "\n",
        "def create_moire_pattern(width, height, frequency=5, angle=30, intensity=128):\n",
        "    \"\"\"\n",
        "    Creates a moiré pattern with specified frequency, angle, and intensity.\n",
        "\n",
        "    :param width: Width of the pattern.\n",
        "    :param height: Height of the pattern.\n",
        "    :param frequency: Frequency of the sine waves.\n",
        "    :param angle: Angle of the pattern in degrees.\n",
        "    :param intensity: Intensity of the pattern (0-255).\n",
        "    :return: Moiré pattern as a numpy array.\n",
        "    \"\"\"\n",
        "    x = np.linspace(0, width, width)\n",
        "    y = np.linspace(0, height, height)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Convert angle to radians\n",
        "    theta = np.deg2rad(angle)\n",
        "\n",
        "    # Generate sinusoidal pattern\n",
        "    pattern = np.sin(2 * np.pi * frequency * (np.cos(theta) * X + np.sin(theta) * Y))\n",
        "\n",
        "    # Normalize the pattern to 0-255 range\n",
        "    pattern_normalized = ((pattern + 1) / 2 * intensity).astype(np.uint8)\n",
        "\n",
        "    return pattern_normalized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECVJV3GUStBS"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the scene image\n",
        "scene_image = cv2.imread(image_path)\n",
        "\n",
        "# Ensure the moiré pattern is in a numpy array with the correct dimensions\n",
        "moire_pattern = create_moire_pattern(500 , 500)  #create_moire_pattern(width, height, frequency=5, angle=30, intensity=128)\n",
        "\n",
        "# Resize the moiré pattern to match the scene image dimensions\n",
        "scene_height, scene_width = scene_image.shape[:2]\n",
        "moire_pattern_resized = cv2.resize(moire_pattern, (scene_width, scene_height))\n",
        "\n",
        "# Create an alpha channel for the moiré pattern, assuming a constant alpha value (e.g., 0.5)\n",
        "alpha_value = 0.6\n",
        "alpha_channel = np.full((scene_height, scene_width), alpha_value, dtype=np.float32)\n",
        "\n",
        "# Convert the resized moiré pattern to a 3-channel image\n",
        "moire_pattern_resized_3ch = cv2.cvtColor(moire_pattern_resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# Blend the images using the alpha channel\n",
        "for c in range(0, 3):\n",
        "    scene_image[:, :, c] = (alpha_channel * moire_pattern_resized_3ch[:, :, c] +\n",
        "                            (1 - alpha_channel) * scene_image[:, :, c])\n",
        "\n",
        "# Display the resulting image\n",
        "cv2_imshow(scene_image)\n",
        "\n",
        "# Save the resulting image\n",
        "cv2.imwrite('overlay_result.jpg', scene_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uyhE1Sng0K3"
      },
      "source": [
        "## Adding Glare (after Moire)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQjG3U5aUn2e"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "ori_img = cv2.imread(image_path)\n",
        "image1 = cv2.imread('overlay_result.jpg')\n",
        "\n",
        "# Apply brightness and contrast adjustment\n",
        "brightness = 60  # Increase brightness\n",
        "contrast = 30    # Increase contrast\n",
        "adjusted_image1 = apply_brightness_contrast(image1, brightness, contrast)\n",
        "\n",
        "# Add natural glare effect at a random location\n",
        "glare_intensity = 0.3\n",
        "glare_size = 0.5\n",
        "adjusted_image1_with_glare = add_natural_glare(adjusted_image1, glare_intensity, glare_size)\n",
        "\n",
        "# Show the images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Adjusted Image 1 with Natural Glare')\n",
        "plt.imshow(cv2.cvtColor(adjusted_image1_with_glare, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save the adjusted image\n",
        "cv2.imwrite('adjusted_2025_with_natural_glare.jpg', adjusted_image1_with_glare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVKEyDJR1LL"
      },
      "source": [
        "-------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fgWmqUZiYGI"
      },
      "source": [
        "---------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTFon_pyiX6N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llCd-gVEeM8R"
      },
      "source": [
        "# BBAug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mUeOmukshdhj"
      },
      "outputs": [],
      "source": [
        "!pip install bbaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM97KboOXNDn"
      },
      "outputs": [],
      "source": [
        "# Import the packages we need\n",
        "import inspect\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "import imageio\n",
        "from imgaug.augmentables.bbs import (\n",
        "    BoundingBox,\n",
        "    BoundingBoxesOnImage,\n",
        ")\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgcMA3QGhXXk"
      },
      "outputs": [],
      "source": [
        "from bbaug.policies import policies\n",
        "from bbaug.augmentations import augmentations\n",
        "from bbaug.policies import list_policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_OUgybIu9P1"
      },
      "source": [
        "## BBAug Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxefxsTAhk3l"
      },
      "outputs": [],
      "source": [
        "print(list_policies())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DZCJTbiGhkBT"
      },
      "outputs": [],
      "source": [
        "policies.policies_v0()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "r4YxTJIWuuTC"
      },
      "outputs": [],
      "source": [
        "policies.policies_v1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAr_fEV1vHQ1"
      },
      "outputs": [],
      "source": [
        "policies.policies_v2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn7si2S2vJoF"
      },
      "outputs": [],
      "source": [
        "policies.policies_v3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Fb4qRmvO8q"
      },
      "source": [
        "## Dictionary of the augmentation name to the method reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZQDHsB1hk15"
      },
      "outputs": [],
      "source": [
        "from bbaug.augmentations import NAME_TO_AUGMENTATION\n",
        "NAME_TO_AUGMENTATION # Shows the dictionary of the augmentation name to the method reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An7x5gWfu4eM"
      },
      "source": [
        "## Customs Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJvEZK33hkv4"
      },
      "outputs": [],
      "source": [
        "#Customize the Policies as you need following the dictionary showing above\n",
        "\n",
        "policy = [\n",
        "  [policies.POLICY_TUPLE('Brightness', 0.5, 3),\n",
        "  policies.POLICY_TUPLE('Cutout', 0.6, 6),\n",
        "  policies.POLICY_TUPLE('Contrast', 0.7, 10),\n",
        "  policies.POLICY_TUPLE('Solarize_Add', 0.4, 3),\n",
        "  policies.POLICY_TUPLE('Sharpness', 0.6, 6),\n",
        "  policies.POLICY_TUPLE('Rotate', 0.6, 1),],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdYR7Q1RsCPt"
      },
      "outputs": [],
      "source": [
        "import imgaug as ia\n",
        "\n",
        "img_num = 5551\n",
        "image_path = f'{PATH}/train/train/images/{img_num}.jpg'\n",
        "annotation_path = f'{PATH}/train/train/annotations/{img_num}.txt'\n",
        "\n",
        "im = imageio.imread(image_path)\n",
        "\n",
        "img_shape = im.shape\n",
        "bbs = [bbox]\n",
        "img_aug, bbs_aug = policy_container.apply_augmentation(random_policy, im, bbs, [0])\n",
        "\n",
        "bbs_aug\n",
        "\n",
        "# visualize_yolo_annotations(image_path, annotation_path, class_labels)\n",
        "bbs_aug = BoundingBoxesOnImage([BoundingBox(*box) for box in bbs_aug[:,1:]], img_aug.shape) # Need to convert bounding boxes\n",
        "ia.imshow(bbs_aug.draw_on_image(img_aug, size=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8BfZ03-h03G"
      },
      "outputs": [],
      "source": [
        "policy_container = policies.PolicyContainer(\n",
        "    policy,\n",
        "    name_to_augmentation=NAME_TO_AUGMENTATION\n",
        ")\n",
        "random_policy = policy_container.select_random_policy()\n",
        "random_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkq9daaEwVFw"
      },
      "source": [
        "## Path for image and annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uec6XaJYhs5k"
      },
      "outputs": [],
      "source": [
        "img_num = 5551\n",
        "\n",
        "image_path = f'{PATH}/train/train/images/{img_num}.jpg'\n",
        "annotation_path = f'{PATH}/train/train/annotations/{img_num}.txt'\n",
        "# visualize_yolo_annotations(image_path, annotation_path, class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx8-i-h7wptX"
      },
      "source": [
        "## read image using 'imageio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6jFyqc6vlR09"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from imgaug.augmentables.bbs import (\n",
        "    BoundingBox,\n",
        "    BoundingBoxesOnImage,\n",
        ")\n",
        "\n",
        "im = imageio.imread('adjusted_2025_with_natural_glare.jpg')\n",
        "\n",
        "print(f'image shape: {im.shape}\\n\\n')\n",
        "im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Xs3GmiifkM"
      },
      "outputs": [],
      "source": [
        "with open(annotation_path, 'r') as file:\n",
        "  annotations = file.readlines()\n",
        "print(f'annotations: {annotations}')\n",
        "\n",
        "for annotation in annotations:\n",
        "  parts = annotation.strip().split()\n",
        "  class_id = int(parts[0])\n",
        "  bbox = list(map(float, parts[1:]))\n",
        "  bbox = denormalize_bbox(im.shape, bbox)\n",
        "\n",
        "print(f'bbox: {bbox}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bZxwJ-o3-e"
      },
      "source": [
        "#Apply augment (looping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUTVMUKYstnp"
      },
      "outputs": [],
      "source": [
        "policy_container = policies.PolicyContainer(\n",
        "    policy,\n",
        "    name_to_augmentation=NAME_TO_AUGMENTATION\n",
        ")\n",
        "random_policy = policy_container.select_random_policy()\n",
        "random_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRuanSpYiHZ2"
      },
      "outputs": [],
      "source": [
        "img_shape = im.shape\n",
        "bbs = [bbox]\n",
        "img_aug, bbs_aug = policy_container.apply_augmentation(random_policy, im, bbs, [0])\n",
        "\n",
        "bbs_aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhnIoBUgpjzy"
      },
      "outputs": [],
      "source": [
        "policy = [[\n",
        "  # policies.POLICY_TUPLE('Brightness', 0.7, 6),\n",
        "  # policies.POLICY_TUPLE('Cutout', 0.6, 6),\n",
        "  # policies.POLICY_TUPLE('Contrast', 0.7, 3),\n",
        "  # policies.POLICY_TUPLE('Solarize_Add', 0.6, 3),\n",
        "  # policies.POLICY_TUPLE('Solarize', 0.6, 10),\n",
        "  # policies.POLICY_TUPLE('Sharpness', 0.6, 6),\n",
        "  policies.POLICY_TUPLE('Rotate', 0.5, 1),\n",
        "   ],\n",
        "]\n",
        "\n",
        "policy_container = policies.PolicyContainer(\n",
        "    policy,\n",
        "    name_to_augmentation=NAME_TO_AUGMENTATION\n",
        ")\n",
        "random_policy = policy_container.select_random_policy()\n",
        "random_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wF4nfoMpI7b"
      },
      "outputs": [],
      "source": [
        "import imgaug as ia\n",
        "\n",
        "for i in range(20):\n",
        "  img_aug, bbs_aug = policy_container.apply_augmentation(random_policy, im, bbs, [0])\n",
        "\n",
        "  bbs_aug = BoundingBoxesOnImage([BoundingBox(*box) for box in bbs_aug[:,1:]], img_aug.shape) # Need to convert bounding boxes\n",
        "  ia.imshow(bbs_aug.draw_on_image(img_aug, size=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HswJH8eFZY3C"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZkKvn-5BARe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SpC16rHODciK",
        "Ej2ICMcYSYuy",
        "u_OUgybIu9P1",
        "An7x5gWfu4eM"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}